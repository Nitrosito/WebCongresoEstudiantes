
<div class ="marco_ponencias">
<h2>Programación Paralela, por J.M. Mantas</h2>
<p>
    La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente,1 operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia. Como el consumo de energía —y por consiguiente la generación de calor— de las computadoras constituye una preocupación en los últimos años.
    La computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.

</p>

</div> <!-- end marco_ponencias-->
<div class="menu_ponencias">
    <ul >
    <li><a href="./index.php?page=ponencias&ponencia=distribuido">Sistemas Distribuidos</a></li>
    <li><a href="./index.php?page=ponencias&ponencia=tiempo_real">Sistemas en Tiempo Real</a></li>
    <li ><a href="./index.php?page=ponencias">Vovler tabla</a></li>
    </ul>
</div>
